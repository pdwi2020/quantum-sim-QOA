from google.cloud import aiplatform

# ==============================================================================
# GCP AND JOB CONFIGURATION
# ==============================================================================
PROJECT_ID = "my-quantum-project-469717"
REGION = "us-central1"
BUCKET_URI = "gs://my-quantum-project-469717-bucket" 
JOB_NAME = "distributed-quantum-sim-run"
IMAGE_URI = "us-central1-docker.pkg.dev/my-quantum-project-469717/my-repo/quantum-sim:v3-distributed"

# --- Machine Specs ---
MACHINE_TYPE = "a2-highgpu-1g"
ACCELERATOR_TYPE = "NVIDIA_TESLA_A100"
ACCELERATOR_COUNT = 1

def main():
    aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)

    # Define the worker pool spec for our multi-node cluster (CORRECTED STRUCTURE)
    worker_pool_specs = [
        # Worker Pool 0: The Primary/Master Node (Replica count must be 1)
        {
            "machine_spec": {
                "machine_type": MACHINE_TYPE,
                "accelerator_type": ACCELERATOR_TYPE,
                "accelerator_count": ACCELERATOR_COUNT,
            },
            "replica_count": 1,
            "container_spec": {
                "image_uri": IMAGE_URI,
            },
        },
        # Worker Pool 1: The Worker Nodes (3 additional replicas)
        {
            "machine_spec": {
                "machine_type": MACHINE_TYPE,
                "accelerator_type": ACCELERATOR_TYPE,
                "accelerator_count": ACCELERATOR_COUNT,
            },
            "replica_count": 3,
            "container_spec": {
                "image_uri": IMAGE_URI,
            },
        }
    ]

    # Create and run the Custom Job
    job = aiplatform.CustomJob(
        display_name=JOB_NAME,
        worker_pool_specs=worker_pool_specs,
    )

    print(f"Submitting multi-node training job to simulate a larger system...")
    job.run()

if __name__ == "__main__":
    main()
